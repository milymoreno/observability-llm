# ğŸ¯ Workshop: IA Generativa para DevOps
## Observabilidad Cloud-Native + LLMs

---

## ğŸ“Œ Objetivo del Workshop

### **Aprender a usar LLMs como "SRE virtuales"**

Al final de este workshop, serÃ¡s capaz de:

âœ… **Analizar logs automÃ¡ticamente** con IA Generativa  
âœ… **Identificar causas raÃ­z** de incidentes en segundos  
âœ… **Generar recomendaciones** de soluciÃ³n sin reglas predefinidas  
âœ… **Reducir MTTR** (Mean Time To Resolution) dramÃ¡ticamente  

### **Sin necesidad de:**
âŒ Instalar Kubernetes  
âŒ Configurar Grafana/Prometheus  
âŒ Infraestructura compleja  

**Solo necesitas:** Python + API Key gratis de Groq

---

## ğŸ“š Agenda (90 minutos)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  15 min  â”‚  IntroducciÃ³n + Demo         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  30 min  â”‚  Demo en Vivo Completa       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  35 min  â”‚  Hands-On (Â¡TÃº lo ejecutas!) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  10 min  â”‚  Q&A + PrÃ³ximos Pasos        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¬ PARTE 1: IntroducciÃ³n (15 min)

### El Problema Actual

**Sin LLMs:**
```
ğŸ“Š Logs complejos â†’ ğŸ˜° Analista confundido â†’ ğŸ• Horas investigando
                  â†’ ğŸ“ DocumentaciÃ³n dispersa â†’ ğŸ’¸ Tiempo perdido
```

**Con LLMs:**
```
ğŸ“Š Logs complejos â†’ ğŸ¤– LLM analiza â†’ âš¡ SoluciÃ³n en segundos
                                   â†’ ğŸ’¡ ExplicaciÃ³n clara
                                   â†’ ğŸ¯ Acciones priorizadas
```

### Â¿QuÃ© es Observabilidad?

Los **3 pilares:**
1. ğŸ“ **Logs** - QuÃ© estÃ¡ pasando (eventos discretos)
2. ğŸ“Š **MÃ©tricas** - NÃºmeros (CPU, memoria, latencia)
3. ğŸ” **Trazas** - Viaje de una request por tus servicios

### Â¿Por quÃ© LLMs?

- âœ… **Comprenden contexto** como un humano
- âœ… **No necesitan reglas** para cada tipo de error
- âœ… **Aprenden de los logs** directamente
- âœ… **Explican en lenguaje natural**

---

## ğŸš€ PARTE 2: Demo en Vivo (30 min)

### Demo RÃ¡pida (2 minutos)

**Â¡Veamos el agente en acciÃ³n!**

```bash
# Generar un incidente simulado
python datasets/generate_logs.py

# El agente LLM lo analiza
python agent/insight_agent.py datasets/sample_logs.txt
```

**Resultado esperado:**
```
ğŸ¤– AnÃ¡lisis del Agente LLM:

1. RESUMEN: Pool de conexiones a la BD agotado
2. CAUSA: Conexiones no se liberan correctamente
3. SEVERIDAD: CRÃTICA âš ï¸
4. ACCIONES:
   - Reiniciar pool de conexiones
   - Aumentar lÃ­mite 50 â†’ 100
   - Revisar cÃ³digo que maneja conexiones
5. INFO ADICIONAL: Circuit breaker activado
```

---

### Arquitectura del Workshop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                     â”‚
â”‚  datasets/generate_logs.py                          â”‚
â”‚  (Simula incidentes realistas)                      â”‚
â”‚         â”‚                                           â”‚
â”‚         â–¼                                           â”‚
â”‚  ğŸ“ sample_logs.txt                                 â”‚
â”‚  (Logs generados)                                   â”‚
â”‚         â”‚                                           â”‚
â”‚         â–¼                                           â”‚
â”‚  agent/insight_agent.py                             â”‚
â”‚  (Analiza con LLM vÃ­a Groq API)                     â”‚
â”‚         â”‚                                           â”‚
â”‚         â–¼                                           â”‚
â”‚  ğŸ’¡ Insights + Recomendaciones                      â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Escenario 1: Database Connection Failure

**Logs simulados:**
```
2025-11-29 10:15:32 ERROR [auth-service] Connection pool exhausted
2025-11-29 10:15:33 ERROR [auth-service] Database connection timeout
2025-11-29 10:15:35 WARN  [api-gateway] Upstream service not responding
2025-11-29 10:15:40 ERROR [api-gateway] 502 Bad Gateway
2025-11-29 10:15:45 ERROR [auth-service] Too many connections
```

**AnÃ¡lisis del LLM:**
- ğŸ”´ **Problema:** Pool de conexiones agotado (50/50)
- ğŸ” **Causa raÃ­z:** Conexiones no se cierran (leak probable)
- âš¡ **SoluciÃ³n inmediata:** Reiniciar servicio
- ğŸ› ï¸ **SoluciÃ³n permanente:** Revisar manejo de conexiones

---

### Escenario 2: Memory Leak

**Logs simulados:**
```
2025-11-29 10:20:15 WARN  [user-service] Heap usage: 85%
2025-11-29 10:20:30 WARN  [user-service] Heap usage: 92%
2025-11-29 10:20:45 ERROR [user-service] OutOfMemoryError
2025-11-29 10:20:46 CRITICAL [user-service] Service crashed
```

**AnÃ¡lisis del LLM:**
- ğŸ”´ **Problema:** Memory leak progresivo
- ğŸ” **Causa raÃ­z:** Objetos no se liberan del heap
- âš¡ **SoluciÃ³n inmediata:** Reiniciar JVM
- ğŸ› ï¸ **SoluciÃ³n permanente:** Profiling + detectar leaks

---

### Escenario 3: High Latency

**Logs simulados:**
```
2025-11-29 10:25:10 WARN  [payment-api] Response time: 2500ms (SLA: 500ms)
2025-11-29 10:25:15 ERROR [payment-api] Database query timeout
2025-11-29 10:25:20 WARN  [payment-api] Response time: 5000ms
2025-11-29 10:25:25 CRITICAL Circuit breaker OPEN
```

**AnÃ¡lisis del LLM:**
- ğŸŸ  **Problema:** Latencia 10x sobre SLA
- ğŸ” **Causa raÃ­z:** Query lenta en BD + efecto cascada
- âš¡ **SoluciÃ³n inmediata:** Circuit breaker activado (OK)
- ğŸ› ï¸ **SoluciÃ³n permanente:** Optimizar query + cache

---

## ğŸ¯ PARTE 3: Hands-On (35 min)

### âš™ï¸ Setup Inicial (5 min)

#### Paso 1: Obtener API Key GRATIS

ğŸ”— **Ve a:** https://console.groq.com/keys

1. Crea cuenta con tu email
2. Click en "Create API Key"
3. Copia la key (empieza con `gsk_`)

#### Paso 2: Configurar segÃºn tu Sistema

**ğŸ§ Si usas Linux/macOS:**
```bash
export GROQ_API_KEY="gsk_tu_key_aqui"
pip3 install requests
```

**ğŸªŸ Si usas Windows (PowerShell):**
```powershell
$env:GROQ_API_KEY="gsk_tu_key_aqui"
pip install requests
```

**ğŸªŸ Si usas Windows (CMD):**
```cmd
set GROQ_API_KEY=gsk_tu_key_aqui
pip install requests
```

#### Paso 3: Clonar el Repositorio

```bash
git clone https://github.com/milymoreno/observability-llm.git
cd observability-llm
```

**ğŸ“¦ Repositorio:** https://github.com/milymoreno/observability-llm

---

### ğŸƒ Ejercicio 1: Ejecutar Demo Completa (10 min)

**ğŸ§ Linux/macOS:**
```bash
bash demo_completo.sh
```

**ğŸªŸ Windows:**
```cmd
demo_windows.bat
```

**Â¿QuÃ© hace este script?**
1. âœ… Verifica que `GROQ_API_KEY` estÃ© configurada
2. âœ… Genera logs del escenario 1 (Database Connection)
3. âœ… El agente LLM los analiza automÃ¡ticamente
4. âœ… Muestra insights y recomendaciones

**Resultado esperado:**
```
âœ… API Key configurada
ğŸ“ Generando logs de incidente...
ğŸ¤– Analizando con el Agente LLM...

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ANÃLISIS DE INCIDENTE - LLM
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. RESUMEN DEL INCIDENTE
   Pool de conexiones completamente agotado...

2. CAUSA PROBABLE
   Conexiones no se liberan correctamente...

3. SEVERIDAD: CRÃTICA
   ...

4. ACCIONES RECOMENDADAS
   - Inmediato: Reiniciar pool de conexiones
   - Corto plazo: Aumentar lÃ­mite...
   ...
```

---

### ğŸƒ Ejercicio 2: Probar Diferentes Escenarios (10 min)

#### Generar logs manualmente:

```bash
python datasets/generate_logs.py
```

**MenÃº interactivo:**
```
Escenarios disponibles:
  1. Database Connection      â­ (Recomendado)
  2. Memory Leak
  3. High Latency
  4. Disk Full
  5. Todos los escenarios
  0. Salir

Selecciona un escenario (0-5): _
```

**Tu tarea:**
1. Selecciona escenario **2** (Memory Leak)
2. Espera 10-15 segundos
3. Presiona `Ctrl+C` para detener
4. Analiza con el agente:
   ```bash
   python agent/insight_agent.py datasets/sample_logs.txt
   ```
5. **Compara** el anÃ¡lisis con el del escenario 1

**Preguntas para reflexionar:**
- Â¿El LLM identificÃ³ correctamente el problema?
- Â¿Las recomendaciones son accionables?
- Â¿QuÃ© diferencias ves entre escenarios?

---

### ğŸƒ Ejercicio 3: Modificar el Prompt (10 min)

**Objetivo:** Personalizar el anÃ¡lisis del LLM

#### Abre el archivo del agente:
```bash
# Linux/macOS
nano agent/insight_agent.py

# Windows
notepad agent/insight_agent.py
```

#### Encuentra la funciÃ³n `analyze_logs_groq()`:

```python
def analyze_logs_groq(logs, api_key):
    prompt = f"""
    Eres un experto SRE analizando logs de producciÃ³n.
    
    Analiza los siguientes logs e identifica:
    1. Resumen del incidente
    2. Causa raÃ­z probable
    3. Nivel de severidad (BAJA/MEDIA/ALTA/CRÃTICA)
    4. Acciones recomendadas (priorizadas)
    5. InformaciÃ³n adicional relevante
    
    LOGS:
    {logs}
    """
```

#### Modifica el prompt:

**Ejemplo 1:** MÃ¡s tÃ©cnico
```python
prompt = f"""
Eres un SRE senior con 10 aÃ±os de experiencia.

Analiza estos logs de producciÃ³n y genera:
1. Executive Summary (2 lÃ­neas)
2. Root Cause Analysis (detallado)
3. Severidad (P1/P2/P3/P4)
4. Runbook de mitigaciÃ³n (paso a paso)
5. Post-mortem inicial
6. MÃ©tricas afectadas

LOGS:
{logs}
"""
```

**Ejemplo 2:** MÃ¡s simple
```python
prompt = f"""
Explica estos logs como si fuera para un junior developer.

Â¿QuÃ© estÃ¡ roto? Â¿Por quÃ©? Â¿CÃ³mo arreglarlo?

LOGS:
{logs}
"""
```

#### Prueba tu modificaciÃ³n:
```bash
python agent/insight_agent.py datasets/sample_logs.txt
```

---

### ğŸƒ Ejercicio 4: Ver Dashboard Visual (5 min)

#### Abre el dashboard en tu navegador:

**ğŸ§ Linux:**
```bash
xdg-open dashboard.html
```

**ğŸ macOS:**
```bash
open dashboard.html
```

**ğŸªŸ Windows:**
```cmd
start dashboard.html
```

**Â¿QuÃ© verÃ¡s?**
- ğŸ“Š MÃ©tricas en tiempo real (simuladas)
- ğŸ“ Vista de logs con colores por severidad
- ğŸ¤– AnÃ¡lisis del LLM pre-cargado
- ğŸ¨ Interfaz estilo Grafana

**Nota:** Este dashboard es HTML estÃ¡tico para demostraciÃ³n.
En producciÃ³n, conectarÃ­as Grafana real con Loki/Prometheus.

---

## ğŸ’¡ PARTE 4: Q&A + PrÃ³ximos Pasos (10 min)

### ğŸ¤” Preguntas Frecuentes

**Q: Â¿Groq es gratis?**  
A: âœ… SÃ­, tier gratis generoso. Suficiente para desarrollo y demos.

**Q: Â¿Puedo usar otro LLM?**  
A: âœ… SÃ­, el cÃ³digo estÃ¡ preparado para Ollama local tambiÃ©n.

**Q: Â¿Funciona en producciÃ³n?**  
A: âœ… SÃ­, pero necesitas:
   - Rate limiting
   - Manejo de errores robusto
   - CachÃ© de anÃ¡lisis
   - Monitoreo del LLM mismo

**Q: Â¿QuÃ© pasa con la privacidad de logs?**  
A: âš ï¸ **Importante:**
   - Anonimiza datos sensibles antes de enviar
   - O usa Ollama local (privado al 100%)
   - Groq no entrena con tus datos

**Q: Â¿Funciona para logs en espaÃ±ol?**  
A: âœ… SÃ­, los LLMs son multilingÃ¼es.

---

### ğŸš€ PrÃ³ximos Pasos

#### ğŸ”° Nivel BÃ¡sico: PersonalizaciÃ³n

1. **Modificar prompts** para tu caso de uso
2. **Crear nuevos escenarios** en `generate_logs.py`
3. **Agregar formatos de logs** especÃ­ficos de tu empresa

#### ğŸ”¸ Nivel Intermedio: IntegraciÃ³n

1. **Conectar con Grafana/Loki**
   - Loki como source de logs
   - Grafana para visualizaciÃ³n
   - Agente LLM como webhook

2. **Automatizar anÃ¡lisis**
   - Trigger en cada alerta
   - Enviar anÃ¡lisis a Slack/Teams
   - Guardar en base de datos

3. **Usar Ollama local**
   ```bash
   # Instalar Ollama
   curl https://ollama.ai/install.sh | sh
   
   # Descargar modelo
   ollama pull llama3.2
   
   # Modificar insight_agent.py para usar Ollama
   ```

#### ğŸ”¹ Nivel Avanzado: ProducciÃ³n

1. **Pipeline completo**
   ```
   Logs â†’ Loki â†’ Alerta â†’ Agente LLM â†’ Slack â†’ PagerDuty
   ```

2. **AnÃ¡lisis histÃ³rico**
   - Base de datos de anÃ¡lisis
   - Patrones recurrentes
   - Dashboard de insights

3. **Fine-tuning**
   - Entrenar modelo con logs reales
   - Optimizar prompts con ejemplos
   - A/B testing de modelos

---

### ğŸ“š Recursos Adicionales

#### ğŸ”— Links Ãštiles

- **Repositorio:** https://github.com/milymoreno/observability-llm
- **Groq API:** https://console.groq.com/keys
- **Groq Docs:** https://console.groq.com/docs/quickstart
- **Ollama:** https://ollama.ai/
- **Loki Docs:** https://grafana.com/docs/loki/

#### ğŸ“– DocumentaciÃ³n del Repo

- `README.md` - Inicio rÃ¡pido
- `WORKSHOP_COMPLETO.md` - Esta presentaciÃ³n
- `agent/insight_agent.py` - CÃ³digo del agente (comentado)
- `datasets/generate_logs.py` - Generador de logs

#### ğŸ¥ Para Aprender MÃ¡s

- Observability 101: https://opentelemetry.io/docs/
- LLMs for DevOps: (buscar en YouTube)
- SRE Books: https://sre.google/books/

---

### ğŸ¯ Casos de Uso Reales

#### 1. AnÃ¡lisis Post-Mortem AutomÃ¡tico
**Antes:** 2-3 horas escribiendo post-mortem  
**Con LLM:** 5 minutos + revisiÃ³n humana

#### 2. Onboarding de SREs Junior
**Antes:** 6 meses aprendiendo todos los sistemas  
**Con LLM:** "Copiloto" que explica cada incidente

#### 3. ReducciÃ³n de MTTR
**Antes:** 45 min promedio para resolver incidentes  
**Con LLM:** 15 min (anÃ¡lisis en segundos + fix)

#### 4. Alertas Enriquecidas
**Antes:** "Error 500 en payment-api"  
**Con LLM:** "Error 500 causado por timeout en BD. Pool de conexiones agotado. Aumentar lÃ­mite o revisar query lenta en transactions."

#### 5. DocumentaciÃ³n AutomÃ¡tica
**Antes:** Runbooks desactualizados  
**Con LLM:** Runbooks generados automÃ¡ticamente de anÃ¡lisis histÃ³rico

---

## ğŸ† Resumen del Workshop

### âœ… Lo que aprendiste hoy:

1. âœ… **QuÃ© es observabilidad** y sus 3 pilares
2. âœ… **CÃ³mo los LLMs** pueden actuar como SRE virtuales
3. âœ… **Configurar** el agente LLM con Groq API
4. âœ… **Generar** logs simulados de incidentes realistas
5. âœ… **Analizar** logs automÃ¡ticamente
6. âœ… **Modificar** prompts para personalizar anÃ¡lisis
7. âœ… **Visualizar** en dashboard HTML

### ğŸ¯ Puntos Clave

- ğŸ’¡ **LLMs comprenden contexto** sin reglas predefinidas
- âš¡ **Reducen MTTR** dramÃ¡ticamente (horas â†’ minutos)
- ğŸŒ **Multiplataforma** (Windows, Linux, macOS)
- ğŸš€ **Sin infraestructura** compleja (solo Python + API key)
- ğŸ”§ **Extensible** y personalizable para tu caso de uso

### ğŸ“¦ LlÃ©vate a Casa

1. **Repositorio clonado:** https://github.com/milymoreno/observability-llm
2. **API Key configurada:** https://console.groq.com/keys
3. **Conocimiento:** CÃ³mo aplicar LLMs a observabilidad
4. **Red:** Contactos de otros participantes

---

## ğŸ™ Â¡Gracias por Participar!

### ğŸ“§ Mantente en Contacto

- **GitHub:** https://github.com/milymoreno
- **Repo del Workshop:** https://github.com/milymoreno/observability-llm
- **Issues/Preguntas:** Abre un issue en el repo

### â­ Si te gustÃ³ el workshop:

```bash
# Dale una estrella al repo
git clone https://github.com/milymoreno/observability-llm.git
cd observability-llm
# Abre GitHub y dale â­
```

### ğŸ“¢ Comparte tu Experiencia

- Twitter/X: Usa #ObservabilityLLM
- LinkedIn: Comparte quÃ© aprendiste
- Blog: Escribe sobre tu implementaciÃ³n

---

## ğŸ¬ Â¡AcciÃ³n Final!

### Tu misiÃ³n (si decides aceptarla):

1. **Esta semana:**
   - Ejecuta el workshop con logs de tu empresa (anonimizados)
   - Modifica los prompts para tu caso de uso

2. **Este mes:**
   - Integra con tu stack de observabilidad actual
   - Crea un POC (Proof of Concept) en un ambiente de staging

3. **Este trimestre:**
   - Implementa en producciÃ³n
   - Mide el impacto (MTTR, satisfacciÃ³n del equipo)
   - Comparte tus resultados con la comunidad

---

# ğŸš€ Â¡Que la observabilidad y la IA te acompaÃ±en!

**Workshop creado con â¤ï¸ para la comunidad DevOps/SRE**

*Repositorio:* https://github.com/milymoreno/observability-llm
