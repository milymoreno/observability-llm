# ğŸ¯ Workshop: IA Generativa para DevOps
## Observabilidad Cloud-Native + LLMs

---

## ï¿½â€ğŸ’» PresentaciÃ³n

### Mildred Moreno

**Los equipos de DevOps viven ahogados en logs y alertas.**

Yo uso **IA generativa, automatizaciÃ³n y arquitectura cloud** para transformar ese caos en claridad: causas raÃ­z, anÃ¡lisis y acciones inmediatas.

**Â¿QuiÃ©n soy?**
- ğŸ“ Ingeniera y MagÃ­ster en Ciencias de la ComputaciÃ³n
- â˜ï¸ AWS Solutions Architect Certified
- ğŸ¤– Futura Doctora en IA
- ğŸ’¼ Especialista en DevOps, Cloud y Observabilidad

**Hoy veremos cÃ³mo la IA puede revolucionar DevOps y la observabilidad.**

---

## ï¿½ğŸ“Œ Objetivo del Workshop

### **Aprender a usar LLMs como "SRE virtuales"**

Al final de este workshop, serÃ¡s capaz de:

âœ… **Analizar logs automÃ¡ticamente** con IA Generativa  
âœ… **Identificar causas raÃ­z** de incidentes en segundos  
âœ… **Generar recomendaciones** de soluciÃ³n sin reglas predefinidas  
âœ… **Reducir MTTR** (Mean Time To Resolution) dramÃ¡ticamente  

### **Sin necesidad de:**
âŒ Instalar Kubernetes  
âŒ Configurar Grafana/Prometheus  
âŒ Infraestructura compleja  

**Solo necesitas:** Python + API Key gratis de Groq

---

## ğŸ“š Agenda (90 minutos)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  15 min  â”‚  IntroducciÃ³n + Demo         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  30 min  â”‚  Demo en Vivo Completa       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  35 min  â”‚  Hands-On (Â¡TÃº lo ejecutas!) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  10 min  â”‚  Q&A + PrÃ³ximos Pasos        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¬ PARTE 1: IntroducciÃ³n (15 min)

### El Problema Actual

**Sin LLMs:**
```
ğŸ“Š Logs complejos â†’ ğŸ˜° Analista confundido â†’ ğŸ• Horas investigando
                  â†’ ğŸ“ DocumentaciÃ³n dispersa â†’ ğŸ’¸ Tiempo perdido
```

**Con LLMs:**
```
ğŸ“Š Logs complejos â†’ ğŸ¤– LLM analiza â†’ âš¡ SoluciÃ³n en segundos
                                   â†’ ğŸ’¡ ExplicaciÃ³n clara
                                   â†’ ğŸ¯ Acciones priorizadas
```

### Â¿QuÃ© es Observabilidad?

Los **3 pilares:**
1. ğŸ“ **Logs** - QuÃ© estÃ¡ pasando (eventos discretos)
2. ğŸ“Š **MÃ©tricas** - NÃºmeros (CPU, memoria, latencia)
3. ğŸ” **Trazas** - Viaje de una request por tus servicios

### Â¿Por quÃ© LLMs?

- âœ… **Comprenden contexto** como un humano
- âœ… **No necesitan reglas** para cada tipo de error
- âœ… **Aprenden de los logs** directamente
- âœ… **Explican en lenguaje natural**

---

## ï¿½ Â¿QuÃ© son los "Insights"?

### DefiniciÃ³n

Un **insight** es una **comprensiÃ³n profunda y accionable** extraÃ­da de datos complejos.

**En observabilidad tradicional:**
```
ğŸ“Š Logs crudos â†’ ğŸ§‘ Humano lee â†’ ğŸ¤” Humano analiza â†’ ğŸ’­ Humano concluye
(5-30 minutos por incidente)
```

**Con LLM generando insights:**
```
ğŸ“Š Logs crudos â†’ ğŸ¤– LLM analiza â†’ ğŸ’¡ Insight automÃ¡tico
(5-10 segundos)
```

### CaracterÃ­sticas de un Buen Insight

1. **Accionable** âœ…
   - No solo describe el problema
   - Sugiere **quÃ© hacer** para solucionarlo

2. **Contextualizado** ğŸ“‹
   - Explica **por quÃ©** estÃ¡ pasando
   - Relaciona mÃºltiples sÃ­ntomas

3. **Priorizado** ğŸ¯
   - Indica **severidad** (Â¿quÃ© tan urgente?)
   - Ordena acciones por **impacto**

4. **Comprensible** ğŸ’¬
   - En lenguaje natural (no cÃ³digo)
   - Para cualquier nivel tÃ©cnico

### Ejemplo: Log vs Insight

**Log crudo:**
```
2025-11-29 10:15:32 ERROR [auth-service] Connection pool exhausted
2025-11-29 10:15:33 ERROR [auth-service] Database timeout 30s
2025-11-29 10:15:35 WARN  [api-gateway] Upstream not responding
2025-11-29 10:15:45 ERROR [auth-service] Too many connections
```

**Insight generado por LLM:**
```
ğŸ”´ CRÃTICO: Pool de conexiones a la base de datos agotado

CAUSA RAÃZ:
- Las conexiones no se liberan despuÃ©s de usarse (leak)
- LÃ­mite de 50 conexiones alcanzado constantemente
- Transacciones abiertas sin cerrar

IMPACTO:
- Servicio auth-service completamente no disponible
- 95% de errores en Ãºltimos 5 minutos
- Afecta a todos los usuarios (autenticaciÃ³n caÃ­da)

ACCIONES INMEDIATAS:
1. Reiniciar pool de conexiones del auth-service (2 min)
2. Aumentar lÃ­mite temporal: 50 â†’ 100 conexiones (5 min)
3. Revisar cÃ³digo que abre conexiones DB (30 min)
4. Implementar timeout mÃ¡s agresivo para liberar (15 min)

PREVENCIÃ“N:
- Monitorear conexiones abiertas por tiempo
- Alertar cuando pool > 80% ocupado
- Code review: verificar try-finally en DB access
```

**Diferencia:**
- âŒ Log: "Algo estÃ¡ roto con las conexiones"
- âœ… Insight: "Por quÃ© estÃ¡ roto + CÃ³mo arreglarlo + CÃ³mo evitarlo"

---

## ï¿½ğŸš€ PARTE 2: Demo en Vivo (30 min)

### Demo RÃ¡pida (2 minutos)

**Â¡Veamos el agente en acciÃ³n!**

```bash
# Generar un incidente simulado
python datasets/generate_logs.py

# El agente LLM lo analiza
python agent/insight_agent.py datasets/sample_logs.txt
```

**Resultado esperado:**
```
ğŸ¤– AnÃ¡lisis del Agente LLM:

1. RESUMEN: Pool de conexiones a la BD agotado
2. CAUSA: Conexiones no se liberan correctamente
3. SEVERIDAD: CRÃTICA âš ï¸
4. ACCIONES:
   - Reiniciar pool de conexiones
   - Aumentar lÃ­mite 50 â†’ 100
   - Revisar cÃ³digo que maneja conexiones
5. INFO ADICIONAL: Circuit breaker activado
```

---

### Arquitectura del Workshop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                     â”‚
â”‚  datasets/generate_logs.py                          â”‚
â”‚  (Simula incidentes realistas)                      â”‚
â”‚         â”‚                                           â”‚
â”‚         â–¼                                           â”‚
â”‚  ğŸ“ sample_logs.txt                                 â”‚
â”‚  (Logs generados)                                   â”‚
â”‚         â”‚                                           â”‚
â”‚         â–¼                                           â”‚
â”‚  agent/insight_agent.py                             â”‚
â”‚  (Analiza con LLM vÃ­a Groq API)                     â”‚
â”‚         â”‚                                           â”‚
â”‚         â–¼                                           â”‚
â”‚  ğŸ’¡ Insights + Recomendaciones                      â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Escenario 1: Database Connection Failure

**Logs simulados:**
```
2025-11-29 10:15:32 ERROR [auth-service] Connection pool exhausted
2025-11-29 10:15:33 ERROR [auth-service] Database connection timeout
2025-11-29 10:15:35 WARN  [api-gateway] Upstream service not responding
2025-11-29 10:15:40 ERROR [api-gateway] 502 Bad Gateway
2025-11-29 10:15:45 ERROR [auth-service] Too many connections
```

**AnÃ¡lisis del LLM:**
- ğŸ”´ **Problema:** Pool de conexiones agotado (50/50)
- ğŸ” **Causa raÃ­z:** Conexiones no se cierran (leak probable)
- âš¡ **SoluciÃ³n inmediata:** Reiniciar servicio
- ğŸ› ï¸ **SoluciÃ³n permanente:** Revisar manejo de conexiones

---

### Escenario 2: Memory Leak

**Logs simulados:**
```
2025-11-29 10:20:15 WARN  [user-service] Heap usage: 85%
2025-11-29 10:20:30 WARN  [user-service] Heap usage: 92%
2025-11-29 10:20:45 ERROR [user-service] OutOfMemoryError
2025-11-29 10:20:46 CRITICAL [user-service] Service crashed
```

**AnÃ¡lisis del LLM:**
- ğŸ”´ **Problema:** Memory leak progresivo
- ğŸ” **Causa raÃ­z:** Objetos no se liberan del heap
- âš¡ **SoluciÃ³n inmediata:** Reiniciar JVM
- ğŸ› ï¸ **SoluciÃ³n permanente:** Profiling + detectar leaks

---

### Escenario 3: High Latency

**Logs simulados:**
```
2025-11-29 10:25:10 WARN  [payment-api] Response time: 2500ms (SLA: 500ms)
2025-11-29 10:25:15 ERROR [payment-api] Database query timeout
2025-11-29 10:25:20 WARN  [payment-api] Response time: 5000ms
2025-11-29 10:25:25 CRITICAL Circuit breaker OPEN
```

**AnÃ¡lisis del LLM:**
- ğŸŸ  **Problema:** Latencia 10x sobre SLA
- ğŸ” **Causa raÃ­z:** Query lenta en BD + efecto cascada
- âš¡ **SoluciÃ³n inmediata:** Circuit breaker activado (OK)
- ğŸ› ï¸ **SoluciÃ³n permanente:** Optimizar query + cache

---

## ğŸ¯ PARTE 3: Hands-On (35 min)

### âš™ï¸ Setup Inicial (5 min)

#### Paso 1: Obtener API Key GRATIS

ğŸ”— **Ve a:** https://console.groq.com/keys

1. Crea cuenta con tu email
2. Click en "Create API Key"
3. Copia la key (empieza con `gsk_`)

#### Paso 2: Configurar segÃºn tu Sistema

**ğŸ§ Si usas Linux/macOS:**
```bash
export GROQ_API_KEY="gsk_tu_key_aqui"
pip3 install requests
```

**ğŸªŸ Si usas Windows (PowerShell):**
```powershell
$env:GROQ_API_KEY="gsk_tu_key_aqui"
pip install requests
```

**ğŸªŸ Si usas Windows (CMD):**
```cmd
set GROQ_API_KEY=gsk_tu_key_aqui
pip install requests
```

#### Paso 3: Clonar el Repositorio

```bash
git clone https://github.com/milymoreno/observability-llm.git
cd observability-llm
```

**ğŸ“¦ Repositorio:** https://github.com/milymoreno/observability-llm

---

### ğŸƒ Ejercicio 1: Ejecutar Demo Completa (10 min)

**ğŸ§ Linux/macOS:**
```bash
bash demo_completo.sh
```

**ğŸªŸ Windows:**
```cmd
demo_windows.bat
```

**Â¿QuÃ© hace este script?**
1. âœ… Verifica que `GROQ_API_KEY` estÃ© configurada
2. âœ… Genera logs del escenario 1 (Database Connection)
3. âœ… El agente LLM los analiza automÃ¡ticamente
4. âœ… Muestra insights y recomendaciones

**Resultado esperado:**
```
âœ… API Key configurada
ğŸ“ Generando logs de incidente...
ğŸ¤– Analizando con el Agente LLM...

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ANÃLISIS DE INCIDENTE - LLM
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. RESUMEN DEL INCIDENTE
   Pool de conexiones completamente agotado...

2. CAUSA PROBABLE
   Conexiones no se liberan correctamente...

3. SEVERIDAD: CRÃTICA
   ...

4. ACCIONES RECOMENDADAS
   - Inmediato: Reiniciar pool de conexiones
   - Corto plazo: Aumentar lÃ­mite...
   ...
```

---

### ğŸƒ Ejercicio 2: Probar Diferentes Escenarios (10 min)

#### Generar logs manualmente:

```bash
python datasets/generate_logs.py
```

**MenÃº interactivo:**
```
Escenarios disponibles:
  1. Database Connection      â­ (Recomendado)
  2. Memory Leak
  3. High Latency
  4. Disk Full
  5. Todos los escenarios
  0. Salir

Selecciona un escenario (0-5): _
```

**Tu tarea:**
1. Selecciona escenario **2** (Memory Leak)
2. Espera 10-15 segundos
3. Presiona `Ctrl+C` para detener
4. Analiza con el agente:
   ```bash
   python agent/insight_agent.py datasets/sample_logs.txt
   ```
5. **Compara** el anÃ¡lisis con el del escenario 1

**Preguntas para reflexionar:**
- Â¿El LLM identificÃ³ correctamente el problema?
- Â¿Las recomendaciones son accionables?
- Â¿QuÃ© diferencias ves entre escenarios?

---

### ğŸƒ Ejercicio 3: Modificar el Prompt (10 min)

**Objetivo:** Personalizar el anÃ¡lisis del LLM

#### Abre el archivo del agente:
```bash
# Linux/macOS
nano agent/insight_agent.py

# Windows
notepad agent/insight_agent.py
```

#### Encuentra la funciÃ³n `analyze_logs_groq()`:

```python
def analyze_logs_groq(logs, api_key):
    prompt = f"""
    Eres un experto SRE analizando logs de producciÃ³n.
    
    Analiza los siguientes logs e identifica:
    1. Resumen del incidente
    2. Causa raÃ­z probable
    3. Nivel de severidad (BAJA/MEDIA/ALTA/CRÃTICA)
    4. Acciones recomendadas (priorizadas)
    5. InformaciÃ³n adicional relevante
    
    LOGS:
    {logs}
    """
```

#### Modifica el prompt:

**Ejemplo 1:** MÃ¡s tÃ©cnico
```python
prompt = f"""
Eres un SRE senior con 10 aÃ±os de experiencia.

Analiza estos logs de producciÃ³n y genera:
1. Executive Summary (2 lÃ­neas)
2. Root Cause Analysis (detallado)
3. Severidad (P1/P2/P3/P4)
4. Runbook de mitigaciÃ³n (paso a paso)
5. Post-mortem inicial
6. MÃ©tricas afectadas

LOGS:
{logs}
"""
```

**Ejemplo 2:** MÃ¡s simple
```python
prompt = f"""
Explica estos logs como si fuera para un junior developer.

Â¿QuÃ© estÃ¡ roto? Â¿Por quÃ©? Â¿CÃ³mo arreglarlo?

LOGS:
{logs}
"""
```

#### Prueba tu modificaciÃ³n:
```bash
python agent/insight_agent.py datasets/sample_logs.txt
```

---

### ğŸƒ Ejercicio 4: Ver Dashboard Visual (5 min)

#### Abre el dashboard en tu navegador:

**ğŸ§ Linux:**
```bash
xdg-open dashboard.html
```

**ğŸ macOS:**
```bash
open dashboard.html
```

**ğŸªŸ Windows:**
```cmd
start dashboard.html
```

**Â¿QuÃ© verÃ¡s?**
- ğŸ“Š MÃ©tricas en tiempo real (simuladas)
- ğŸ“ Vista de logs con colores por severidad
- ğŸ¤– AnÃ¡lisis del LLM pre-cargado
- ğŸ¨ Interfaz estilo Grafana

**Nota:** Este dashboard es HTML estÃ¡tico para demostraciÃ³n.
En producciÃ³n, conectarÃ­as Grafana real con Loki/Prometheus.

---

### ğŸ“Š Â¿Es posible ver logs en Grafana?

**SÃ, absolutamente.** De hecho, es el camino recomendado para producciÃ³n.

#### Stack Completo de Observabilidad

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  APLICACIONES / SERVICIOS                          â”‚
â”‚  (Generan logs, mÃ©tricas, trazas)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LOKI   â”‚  â”‚PROMETHEUSâ”‚  â”‚  TEMPO    â”‚
â”‚ (Logs)  â”‚  â”‚(MÃ©tricas)â”‚  â”‚ (Trazas)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚              â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   GRAFANA   â”‚
            â”‚(Visualiza)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   AGENTE LLM       â”‚
         â”‚ (Analiza + Insight)â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### IntegraciÃ³n con Grafana

**1. Loki como fuente de logs**
```yaml
# grafana/datasources.yaml
apiVersion: 1
datasources:
  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    isDefault: true
```

**2. Query de logs en Grafana**
```logql
# LogQL (lenguaje de query de Loki)
{service="auth-service"} |= "ERROR" | json
```

**3. Trigger del agente LLM**

Cuando Grafana detecta anomalÃ­as:
```
Grafana Alerta â†’ Webhook â†’ Agente LLM â†’ AnÃ¡lisis â†’ Slack/PagerDuty
```

#### Flujo Completo en ProducciÃ³n

```
1. RECOLECCIÃ“N
   App â†’ Promtail â†’ Loki (almacena logs)

2. VISUALIZACIÃ“N
   Loki â†’ Grafana (dashboards + alertas)

3. DETECCIÃ“N
   Grafana detecta patrÃ³n anÃ³malo â†’ Dispara alerta

4. ANÃLISIS IA
   Webhook llama al agente LLM con logs relevantes

5. INSIGHT
   LLM genera anÃ¡lisis + recomendaciones

6. NOTIFICACIÃ“N
   Resultado â†’ Slack/Teams/PagerDuty con contexto completo

7. ACCIÃ“N
   SRE tiene causa raÃ­z + pasos a seguir inmediatamente
```

#### Â¿Por quÃ© NO usamos Grafana en este workshop?

**Razones prÃ¡cticas:**

1. **InstalaciÃ³n compleja** 
   - Requiere Kubernetes o Docker Compose
   - Loki + Prometheus + Grafana = 30-45 min setup
   - Participantes pueden tener problemas de permisos/red

2. **Espacio en disco**
   - Stack completo necesita 2-3 GB mÃ­nimo
   - No todos tienen espacio disponible

3. **Enfoque del workshop**
   - Queremos mostrar el **concepto** del agente LLM
   - La UI de Grafana es secundaria
   - Mejor usar tiempo en modificar prompts y entender IA

**Para producciÃ³n:**
- âœ… Usa Grafana + Loki (mejor prÃ¡ctica)
- âœ… Configura alertas con webhooks
- âœ… Integra el agente LLM en tu pipeline

**Para este workshop:**
- âœ… Dashboard HTML muestra el concepto
- âœ… Nos enfocamos en el agente LLM
- âœ… DespuÃ©s pueden integrar con su Grafana existente

#### Demo Opcional: Grafana Cloud (GRATIS)

Si quieres ver Grafana real durante el workshop:

1. **Ve a:** https://grafana.com/auth/sign-up
2. **Crea cuenta** gratuita (14 dÃ­as trial completo)
3. **Accede** a tu instancia cloud
4. **Crea dashboard** con logs de ejemplo

**Ventajas:**
- âœ… Listo en 5 minutos
- âœ… Sin instalaciÃ³n local
- âœ… Accesible desde cualquier lado
- âœ… UI profesional

**Para conectar el agente:**
```python
# En tu cÃ³digo
def send_to_grafana_cloud(analysis, api_key):
    # Enviar insight como anotaciÃ³n
    # O crear alert personalizada
    pass
```

---

## ğŸ’¡ PARTE 4: Q&A + PrÃ³ximos Pasos (10 min)

### ğŸ¤” Preguntas Frecuentes

**Q: Â¿Groq es gratis?**  
A: âœ… SÃ­, tier gratis generoso. Suficiente para desarrollo y demos.

**Q: Â¿Puedo usar otro LLM?**  
A: âœ… SÃ­, el cÃ³digo estÃ¡ preparado para Ollama local tambiÃ©n.

**Q: Â¿Funciona en producciÃ³n?**  
A: âœ… SÃ­, pero necesitas:
   - Rate limiting
   - Manejo de errores robusto
   - CachÃ© de anÃ¡lisis
   - Monitoreo del LLM mismo

**Q: Â¿QuÃ© pasa con la privacidad de logs?**  
A: âš ï¸ **Importante:**
   - Anonimiza datos sensibles antes de enviar
   - O usa Ollama local (privado al 100%)
   - Groq no entrena con tus datos

**Q: Â¿Funciona para logs en espaÃ±ol?**  
A: âœ… SÃ­, los LLMs son multilingÃ¼es.

---

### ğŸš€ PrÃ³ximos Pasos

#### ğŸ”° Nivel BÃ¡sico: PersonalizaciÃ³n

1. **Modificar prompts** para tu caso de uso
2. **Crear nuevos escenarios** en `generate_logs.py`
3. **Agregar formatos de logs** especÃ­ficos de tu empresa

#### ğŸ”¸ Nivel Intermedio: IntegraciÃ³n

1. **Conectar con Grafana/Loki**
   - Loki como source de logs
   - Grafana para visualizaciÃ³n
   - Agente LLM como webhook

2. **Automatizar anÃ¡lisis**
   - Trigger en cada alerta
   - Enviar anÃ¡lisis a Slack/Teams
   - Guardar en base de datos

3. **Usar Ollama local**
   ```bash
   # Instalar Ollama
   curl https://ollama.ai/install.sh | sh
   
   # Descargar modelo
   ollama pull llama3.2
   
   # Modificar insight_agent.py para usar Ollama
   ```

#### ğŸ”¹ Nivel Avanzado: ProducciÃ³n

1. **Pipeline completo**
   ```
   Logs â†’ Loki â†’ Alerta â†’ Agente LLM â†’ Slack â†’ PagerDuty
   ```

2. **AnÃ¡lisis histÃ³rico**
   - Base de datos de anÃ¡lisis
   - Patrones recurrentes
   - Dashboard de insights

3. **Fine-tuning**
   - Entrenar modelo con logs reales
   - Optimizar prompts con ejemplos
   - A/B testing de modelos

---

### ğŸ“š Recursos Adicionales

#### ğŸ”— Links Ãštiles

- **Repositorio:** https://github.com/milymoreno/observability-llm
- **Groq API:** https://console.groq.com/keys
- **Groq Docs:** https://console.groq.com/docs/quickstart
- **Ollama:** https://ollama.ai/
- **Loki Docs:** https://grafana.com/docs/loki/

#### ğŸ“– DocumentaciÃ³n del Repo

- `README.md` - Inicio rÃ¡pido
- `WORKSHOP_COMPLETO.md` - Esta presentaciÃ³n
- `agent/insight_agent.py` - CÃ³digo del agente (comentado)
- `datasets/generate_logs.py` - Generador de logs

#### ğŸ¥ Para Aprender MÃ¡s

- Observability 101: https://opentelemetry.io/docs/
- LLMs for DevOps: (buscar en YouTube)
- SRE Books: https://sre.google/books/

---

### ğŸ¯ Casos de Uso Reales

#### 1. AnÃ¡lisis Post-Mortem AutomÃ¡tico
**Antes:** 2-3 horas escribiendo post-mortem  
**Con LLM:** 5 minutos + revisiÃ³n humana

#### 2. Onboarding de SREs Junior
**Antes:** 6 meses aprendiendo todos los sistemas  
**Con LLM:** "Copiloto" que explica cada incidente

#### 3. ReducciÃ³n de MTTR
**Antes:** 45 min promedio para resolver incidentes  
**Con LLM:** 15 min (anÃ¡lisis en segundos + fix)

#### 4. Alertas Enriquecidas
**Antes:** "Error 500 en payment-api"  
**Con LLM:** "Error 500 causado por timeout en BD. Pool de conexiones agotado. Aumentar lÃ­mite o revisar query lenta en transactions."

#### 5. DocumentaciÃ³n AutomÃ¡tica
**Antes:** Runbooks desactualizados  
**Con LLM:** Runbooks generados automÃ¡ticamente de anÃ¡lisis histÃ³rico

---

## ğŸ† Resumen del Workshop

### âœ… Lo que aprendiste hoy:

1. âœ… **QuÃ© es observabilidad** y sus 3 pilares
2. âœ… **CÃ³mo los LLMs** pueden actuar como SRE virtuales
3. âœ… **Configurar** el agente LLM con Groq API
4. âœ… **Generar** logs simulados de incidentes realistas
5. âœ… **Analizar** logs automÃ¡ticamente
6. âœ… **Modificar** prompts para personalizar anÃ¡lisis
7. âœ… **Visualizar** en dashboard HTML

### ğŸ¯ Puntos Clave

- ğŸ’¡ **LLMs comprenden contexto** sin reglas predefinidas
- âš¡ **Reducen MTTR** dramÃ¡ticamente (horas â†’ minutos)
- ğŸŒ **Multiplataforma** (Windows, Linux, macOS)
- ğŸš€ **Sin infraestructura** compleja (solo Python + API key)
- ğŸ”§ **Extensible** y personalizable para tu caso de uso

### ğŸ“¦ LlÃ©vate a Casa

1. **Repositorio clonado:** https://github.com/milymoreno/observability-llm
2. **API Key configurada:** https://console.groq.com/keys
3. **Conocimiento:** CÃ³mo aplicar LLMs a observabilidad
4. **Red:** Contactos de otros participantes

---

## ğŸ™ Â¡Gracias por Participar!

### ğŸ“§ Mantente en Contacto

- **GitHub:** https://github.com/milymoreno
- **Repo del Workshop:** https://github.com/milymoreno/observability-llm
- **Issues/Preguntas:** Abre un issue en el repo

### â­ Si te gustÃ³ el workshop:

```bash
# Dale una estrella al repo
git clone https://github.com/milymoreno/observability-llm.git
cd observability-llm
# Abre GitHub y dale â­
```

### ğŸ“¢ Comparte tu Experiencia

- Twitter/X: Usa #ObservabilityLLM
- LinkedIn: Comparte quÃ© aprendiste
- Blog: Escribe sobre tu implementaciÃ³n

---

## ğŸ¬ Â¡AcciÃ³n Final!

### Tu misiÃ³n (si decides aceptarla):

1. **Esta semana:**
   - Ejecuta el workshop con logs de tu empresa (anonimizados)
   - Modifica los prompts para tu caso de uso

2. **Este mes:**
   - Integra con tu stack de observabilidad actual
   - Crea un POC (Proof of Concept) en un ambiente de staging

3. **Este trimestre:**
   - Implementa en producciÃ³n
   - Mide el impacto (MTTR, satisfacciÃ³n del equipo)
   - Comparte tus resultados con la comunidad

---

# ğŸš€ Â¡Que la observabilidad y la IA te acompaÃ±en!

**Workshop creado con â¤ï¸ para la comunidad DevOps/SRE**

*Repositorio:* https://github.com/milymoreno/observability-llm
